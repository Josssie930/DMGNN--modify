{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_number = random.randint(1, 100)\n",
    "print(random_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "[12, 16, 11, 6, 9, 11, 17, 8, 2, 19, 20, 13, 6, 15, 13, 12, 3, 5, 19, 4, 7, 8, 1, 20, 20, 19, 18, 10, 13, 4, 2, 9, 6, 19, 7, 13, 14, 5, 10]\n",
      "[3, 4, 5, 3, 4, 2, 5, 3, 5, 4, 3, 1, 3, 3, 5, 1, 3, 3, 2, 1, 5, 5, 2, 4, 4, 4, 3, 2, 4, 3, 5, 3, 3, 5, 3, 1, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "node_id_list = []\n",
    "tads_list = []\n",
    "abcompartment_list = []\n",
    "for i in range(39):\n",
    "    node_id_list.append(i)\n",
    "    tads_list.append(random.randint(1, 20))\n",
    "    abcompartment_list.append(random.randint(1, 5))\n",
    "print(node_id_list)\n",
    "print(tads_list)\n",
    "print(abcompartment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 12, 3, 1, 16, 4, 2, 11, 5, 3, 6, 3, 4, 9, 4, 5, 11, 2, 6, 17, 5, 7, 8, 3, 8, 2, 5, 9, 19, 4, 10, 20, 3, 11, 13, 1, 12, 6, 3, 13, 15, 3, 14, 13, 5, 15, 12, 1, 16, 3, 3, 17, 5, 3, 18, 19, 2, 19, 4, 1, 20, 7, 5, 21, 8, 5, 22, 1, 2, 23, 20, 4, 24, 20, 4, 25, 19, 4, 26, 18, 3, 27, 10, 2, 28, 13, 4, 29, 4, 3, 30, 2, 5, 31, 9, 3, 32, 6, 3, 33, 19, 5, 34, 7, 3, 35, 13, 1, 36, 14, 4, 37, 5, 4, 38, 10, 3]\n"
     ]
    }
   ],
   "source": [
    "total_list = [x for y in zip(node_id_list, tads_list, abcompartment_list) for x in y]\n",
    "print(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "print(len(total_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  18   3 ... 199  18   3]\n",
      " [  0   6   2 ... 199   2   1]\n",
      " [  0  19   4 ... 199  14   4]\n",
      " ...\n",
      " [  0  16   4 ... 199   1   5]\n",
      " [  0  20   4 ... 199   6   5]\n",
      " [  0  16   3 ... 199  11   4]]\n",
      "600\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/train/hic/hic_1.txt\n",
      "[[  0  11   2 ... 199   6   1]\n",
      " [  0   7   1 ... 199  15   2]\n",
      " [  0  15   2 ... 199   1   3]\n",
      " ...\n",
      " [  0  19   2 ... 199  17   2]\n",
      " [  0   5   3 ... 199  17   1]\n",
      " [  0   5   5 ... 199  18   5]]\n",
      "600\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/train/hic/hic_2.txt\n",
      "[[  0   4   2 ... 199   9   4]\n",
      " [  0   4   4 ... 199   1   1]\n",
      " [  0  18   5 ... 199   8   2]\n",
      " ...\n",
      " [  0  20   3 ... 199  12   2]\n",
      " [  0  20   4 ... 199   8   5]\n",
      " [  0   5   2 ... 199  14   3]]\n",
      "600\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/train/hic/hic_3.txt\n",
      "[[  0   7   3 ... 199   2   2]\n",
      " [  0   4   4 ... 199   5   2]\n",
      " [  0   2   2 ... 199   1   4]\n",
      " ...\n",
      " [  0   1   5 ... 199  18   4]\n",
      " [  0  13   4 ... 199  18   2]\n",
      " [  0  18   1 ... 199  12   2]]\n",
      "600\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/train/hic/hic_4.txt\n",
      "[[  0  18   4 ... 199  18   1]\n",
      " [  0   1   1 ... 199  11   4]\n",
      " [  0  13   3 ... 199   3   1]\n",
      " ...\n",
      " [  0   9   3 ... 199  16   5]\n",
      " [  0  18   2 ... 199  13   4]\n",
      " [  0   6   4 ... 199   4   4]]\n",
      "600\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/train/hic/hic_5.txt\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "for j in range(1,6):\n",
    "    final_list = []\n",
    "    for times in range(300):\n",
    "        node_id_list = []\n",
    "        tads_list = []\n",
    "        abcompartment_list = []\n",
    "        for i in range(200):\n",
    "            node_id_list.append(i)\n",
    "            tads_list.append(random.randint(1, 20))\n",
    "            abcompartment_list.append(random.randint(1, 5))\n",
    "        #print(node_id_list)\n",
    "        #print(tads_list)\n",
    "        #print(abcompartment_list)\n",
    "        total_list = [x for y in zip(node_id_list, tads_list, abcompartment_list) for x in y]\n",
    "        #print(total_list)\n",
    "        final_list.append(total_list)\n",
    "        #print(\"\\n\")\n",
    "        final_array = np.array(final_list)\n",
    "\n",
    "    print(final_array)\n",
    "    print(len(final_array[0]))\n",
    "    save_path = \"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/train/hic/hic_\" + str(j) + \".txt\"\n",
    "\n",
    "    f = open(save_path,'a')\n",
    "    f.close()\n",
    "    print(save_path)\n",
    "    np.savetxt(save_path, final_array,fmt='%d',delimiter=',')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  18   4 ... 199  16   2]\n",
      " [  0  20   1 ... 199  17   3]\n",
      " [  0   3   3 ... 199  14   2]\n",
      " ...\n",
      " [  0   2   1 ... 199  15   3]\n",
      " [  0  15   3 ... 199  14   2]\n",
      " [  0  13   3 ... 199  19   1]]\n",
      "600\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/test/hic/hic_1.txt\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,2):\n",
    "    final_list = []\n",
    "    for times in range(300):\n",
    "        node_id_list = []\n",
    "        tads_list = []\n",
    "        abcompartment_list = []\n",
    "        for i in range(200):\n",
    "            node_id_list.append(i)\n",
    "            tads_list.append(random.randint(1, 20))\n",
    "            abcompartment_list.append(random.randint(1, 5))\n",
    "        #print(node_id_list)\n",
    "        #print(tads_list)\n",
    "        #print(abcompartment_list)\n",
    "        total_list = [x for y in zip(node_id_list, tads_list, abcompartment_list) for x in y]\n",
    "        #print(total_list)\n",
    "        final_list.append(total_list)\n",
    "        #print(\"\\n\")\n",
    "        final_array = np.array(final_list)\n",
    "\n",
    "    print(final_array)\n",
    "    print(len(final_array[0]))\n",
    "    save_path = \"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/test/hic/hic_\" + str(j) + \".txt\"\n",
    "\n",
    "    f = open(save_path,'a')\n",
    "    f.close()\n",
    "    print(save_path)\n",
    "    np.savetxt(save_path, final_array,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 14  3 ... 38  1  4]\n",
      " [ 0 13  5 ... 38  8  3]\n",
      " [ 0 14  1 ... 38 12  5]\n",
      " ...\n",
      " [ 0  7  4 ... 38  1  3]\n",
      " [ 0 20  4 ... 38 18  5]\n",
      " [ 0  3  2 ... 38 13  3]]\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_array = np.array(final_list)\n",
    "print(final_array)\n",
    "print(len(final_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/cmu/test/walking/walking_1.txt\", final_array,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_10kb.txt\n",
      "[[   10     9     1]\n",
      " [   18    13     1]\n",
      " [   18    18     1]\n",
      " ...\n",
      " [19226 19063     1]\n",
      " [19226 19223     1]\n",
      " [19229 19061     1]]\n",
      "[   10    18    18 ... 19226 19226 19229] [    9    13    18 ... 19063 19223 19061] [1 1 1 ... 1 1 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_50kb.txt\n",
      "[[   2    1    1]\n",
      " [   3    2    2]\n",
      " [   3    3    3]\n",
      " ...\n",
      " [3845 2913    1]\n",
      " [3845 3812    2]\n",
      " [3845 3844    1]]\n",
      "[   2    3    3 ... 3845 3845 3845] [   1    2    3 ... 2913 3812 3844] [1 2 3 ... 1 2 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_100kb.txt\n",
      "[[   1    0    1]\n",
      " [   1    1    5]\n",
      " [   2    0    1]\n",
      " ...\n",
      " [1922 1922    1]\n",
      " [1923 1124    2]\n",
      " [1923 1126    1]]\n",
      "[   1    1    2 ... 1922 1923 1923] [   0    1    0 ... 1922 1124 1126] [1 5 1 ... 1 2 1]\n",
      "[[ 0  1  1 ...  0  0  0]\n",
      " [ 1  5  2 ...  0  0  0]\n",
      " [ 1  2 10 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  3  0]\n",
      " [ 0  0  0 ...  3  1  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "(matrix([[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]), matrix([[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 1, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 2, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 1, 1],\n",
      "        [0, 0, 0, ..., 0, 1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import os\n",
    "\n",
    "import hicstraw\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import math\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.utils import convert\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def load_data(cell_id, chrom):\n",
    "    root = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test\" # 文件夹路径，相对路径or绝对路径都可以\n",
    "    # 获取文件夹所有文件\n",
    "    files_list = os.listdir(root) # 示例 [\"1.txt\",\"2.txt\",\"2.gif\",\"child_folder_name\",\"2.jpg\"]\n",
    "\n",
    "    ## 常见操作\n",
    "    # 1.获取指定后缀（如txt）的文件\n",
    "    filter_files_list_10kb = [fn for fn in files_list if fn.endswith(\"_chrom\"+str(chrom)+\"_10kb.txt\")]\n",
    "    #print(filter_files_list_10kb)\n",
    "    cell_id_name = filter_files_list_10kb[cell_id]\n",
    "    \n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_10kb.txt\"\n",
    "    print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    print(col,row,value)\n",
    "\n",
    "    max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    print(complete_matrix)\n",
    "    #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "    complete_matrix_10kb_test  = complete_matrix[0:200,0:200]\n",
    "    np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_200.txt\", complete_matrix_10kb_test,fmt='%d',delimiter=',')\n",
    "\n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_50kb.txt\"\n",
    "    print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    print(col,row,value)\n",
    "\n",
    "    max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    print(complete_matrix)\n",
    "    #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "    complete_matrix_50kb_test  = complete_matrix[0:40,0:40]\n",
    "    np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_40.txt\", complete_matrix_50kb_test,fmt='%d',delimiter=',')\n",
    "\n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_100kb.txt\"\n",
    "    print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    print(col,row,value)\n",
    "\n",
    "    max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    print(complete_matrix)\n",
    "    #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "    complete_matrix_100kb_test  = complete_matrix[0:20,0:20]\n",
    "    np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_20.txt\", complete_matrix_100kb_test,fmt='%d',delimiter=',')\n",
    "\n",
    "    '''\n",
    "\n",
    "    filter_files_list_50kb = [fn for fn in files_list if fn.endswith(\"_chrom\"+str(chrom)+\"_50kb.txt\")]\n",
    "    #print(filter_files_list_10kb)\n",
    "    cell_id_name = filter_files_list_50kb[cell_id]\n",
    "    \n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/\" + str(cell_id_name)\n",
    "    #print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    #print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    #print(col,row,value)\n",
    "\n",
    "    max_nodes =int (max(col)+1)\n",
    "    print(max_nodes)\n",
    "    t_col = torch.from_numpy(col)\n",
    "    print(t_col)\n",
    "    t_row = torch.from_numpy(row)\n",
    "    print(t_row)\n",
    "    t_value = torch.from_numpy(value)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((t_value,(t_row,t_col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    #print(complete_matrix)\n",
    "    t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    t_complete_matrix_50kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "\n",
    "    filter_files_list_100kb = [fn for fn in files_list if fn.endswith(\"_chrom\"+str(chrom)+\"_100kb.txt\")]\n",
    "    #print(filter_files_list_10kb)\n",
    "    cell_id_name = filter_files_list_100kb[cell_id]\n",
    "    \n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/\" + str(cell_id_name)\n",
    "    #print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    #print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    #print(col,row,value)\n",
    "    max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    #print(complete_matrix)\n",
    "    #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "    t_complete_matrix_10kb_test  = complete_matrix[0:26,0:26]\n",
    "    '''\n",
    "    return complete_matrix_10kb_test,complete_matrix_50kb_test\n",
    "\n",
    "\n",
    "x = load_data(0,1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_26.txt\", x,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class AveargeJoint(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.torso = [8,9,10]\n",
    "        self.left_leg_up = [0,1]\n",
    "        self.left_leg_down = [2,3]\n",
    "        self.right_leg_up = [4,5]\n",
    "        self.right_leg_down = [6,7]\n",
    "        self.head = [11,12,13]\n",
    "        self.left_arm_up = [14,15]\n",
    "        self.left_arm_down = [16,17,18,19]\n",
    "        self.right_arm_up = [20,21]\n",
    "        self.right_arm_down = [22,23,24,25]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_torso = F.avg_pool2d(x[:, :, self.torso], kernel_size=(1, 3))                                              # [N, C, T, V=1]\n",
    "        x_leftlegup = F.avg_pool2d(x[:, :, self.left_leg_up], kernel_size=(1, 2))                                # [N, C, T, V=1]\n",
    "        x_leftlegdown = F.avg_pool2d(x[:, :, self.left_leg_down], kernel_size=(1, 2))                     # [N, C, T, V=1]\n",
    "        x_rightlegup = F.avg_pool2d(x[:,  :, self.right_leg_up], kernel_size=(1, 2))                        # [N, C, T, V=1]\n",
    "        x_rightlegdown = F.avg_pool2d(x[ :, :, self.right_leg_down], kernel_size=(1, 2))                   # [N, C, T, V=1]\n",
    "        x_head = F.avg_pool2d(x[ :, :, self.head], kernel_size=(1, 3))                                              # [N, C, T, V=1]\n",
    "        x_leftarmup = F.avg_pool2d(x[ :, :, self.left_arm_up], kernel_size=(1, 2))                            # [N, C, T, V=1]\n",
    "        x_leftarmdown = F.avg_pool2d(x[ :, :, self.left_arm_down], kernel_size=(1, 4))                 # [N, C, T, V=1]\n",
    "        x_rightarmup = F.avg_pool2d(x[ :, :, self.right_arm_up], kernel_size=(1, 2))                        # [N, C, T, V=1]\n",
    "        x_rightarmdown = F.avg_pool2d(x[ :, :, self.right_arm_down], kernel_size=(1, 4))               # [N, C, T, V=1]\n",
    "        x_part = torch.cat((x_leftlegup, x_leftlegdown, x_rightlegup, x_rightlegdown, x_torso, x_head, x_leftarmup, x_leftarmdown, x_rightarmup, x_rightarmdown), dim=-1)               # [N, C, T, V=1]), dim=-1)        # [N, C, T, 10]\n",
    "        return x_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 20,  2,  1, 17,  4,  2, 20,  2,  3,  7,  1,  4,  2,  3,  5,  3,  3,\n",
      "          6, 18,  1,  7, 10,  1,  8, 15,  5,  9,  5,  1, 10,  2,  2, 11, 11,  3,\n",
      "         12, 16,  3, 13,  4,  3, 14,  6,  2, 15,  8,  3, 16, 19,  1, 17,  3,  2,\n",
      "         18,  6,  5, 19,  5,  5, 20,  4,  3, 21,  4,  1, 22, 20,  3, 23, 19,  2,\n",
      "         24, 19,  1, 25,  2,  3, 26,  1,  5, 27,  9,  5, 28, 16,  1, 29, 14,  5],\n",
      "        [ 0, 14,  1,  1, 11,  3,  2, 13,  3,  3, 15,  1,  4, 11,  5,  5,  5,  4,\n",
      "          6,  7,  5,  7,  6,  2,  8, 12,  4,  9, 17,  3, 10, 11,  2, 11, 16,  3,\n",
      "         12,  9,  1, 13, 19,  5, 14, 20,  1, 15, 13,  5, 16,  7,  5, 17,  1,  5,\n",
      "         18,  9,  3, 19, 20,  1, 20,  1,  2, 21, 11,  2, 22,  1,  2, 23,  5,  4,\n",
      "         24,  3,  2, 25, 13,  5, 26,  1,  1, 27, 19,  4, 28, 11,  3, 29, 12,  2]])\n",
      "torch.Size([2, 90])\n",
      "tensor([[[ 0, 20,  2,  1, 17,  4,  2, 20,  2,  3,  7,  1,  4,  2,  3,  5,  3,\n",
      "           3,  6, 18,  1,  7, 10,  1,  8, 15,  5,  9,  5,  1],\n",
      "         [10,  2,  2, 11, 11,  3, 12, 16,  3, 13,  4,  3, 14,  6,  2, 15,  8,\n",
      "           3, 16, 19,  1, 17,  3,  2, 18,  6,  5, 19,  5,  5],\n",
      "         [20,  4,  3, 21,  4,  1, 22, 20,  3, 23, 19,  2, 24, 19,  1, 25,  2,\n",
      "           3, 26,  1,  5, 27,  9,  5, 28, 16,  1, 29, 14,  5]],\n",
      "\n",
      "        [[ 0, 14,  1,  1, 11,  3,  2, 13,  3,  3, 15,  1,  4, 11,  5,  5,  5,\n",
      "           4,  6,  7,  5,  7,  6,  2,  8, 12,  4,  9, 17,  3],\n",
      "         [10, 11,  2, 11, 16,  3, 12,  9,  1, 13, 19,  5, 14, 20,  1, 15, 13,\n",
      "           5, 16,  7,  5, 17,  1,  5, 18,  9,  3, 19, 20,  1],\n",
      "         [20,  1,  2, 21, 11,  2, 22,  1,  2, 23,  5,  4, 24,  3,  2, 25, 13,\n",
      "           5, 26,  1,  1, 27, 19,  4, 28, 11,  3, 29, 12,  2]]])\n",
      "torch.Size([2, 3, 30])\n"
     ]
    }
   ],
   "source": [
    "x_test = list([[0,20,2,1,17,4,2,20,2,3,7,1,4,2,3,5,3,3,6,18,1,7,10,1,8,15,5,9,5,1,10,2,2,11,11,3,12,16,3,13,4,3,14,6,2,15,8,3,16,19,1,17,3,2,18,6,5,19,5,5,20,4,3,21,4,1,22,20,3,23,19,2,24,19,1,25,2,3,26,1,5,27,9,5,28,16,1,29,14,5,30,7,5,31,2,4,32,10,2,33,19,5,34,1,4,35,5,4,36,11,3,37,11,4,38,10,3],\n",
    "          [0,14,1,1,11,3,2,13,3,3,15,1,4,11,5,5,5,4,6,7,5,7,6,2,8,12,4,9,17,3,10,11,2,11,16,3,12,9,1,13,19,5,14,20,1,15,13,5,16,7,5,17,1,5,18,9,3,19,20,1,20,1,2,21,11,2,22,1,2,23,5,4,24,3,2,25,13,5,26,1,1,27,19,4,28,11,3,29,12,2,30,9,4,31,6,5,32,6,2,33,5,2,34,2,4,35,1,2,36,5,1,37,5,1,38,14,4]])\n",
    "x_new1 = x_test[0][0:90]\n",
    "x_new2 = x_test[1][0:90]\n",
    "x_new = [x_new1,x_new2]\n",
    "\n",
    "out_t = torch.tensor(x_new)\n",
    "print(out_t)\n",
    "print(out_t.shape)\n",
    "out_t = out_t.contiguous().view(2,3,30)   \n",
    "out_t = out_t.permute(0, 1, 2).contiguous()\n",
    "print(out_t)\n",
    "print(out_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10,  1, 10, 11,  4,  2,  4,  7,  4,  8],\n",
      "         [ 7,  3,  6,  6,  8, 10,  3,  9,  5, 13],\n",
      "         [ 2, 12, 12,  5,  9,  8, 21, 11, 21,  7]],\n",
      "\n",
      "        [[ 7,  1,  7,  7,  7,  5,  5,  5,  6,  7],\n",
      "         [ 6, 10, 10,  6, 10,  7, 12, 12,  9, 11],\n",
      "         [ 3, 13, 11, 10,  7, 11, 11,  8, 13, 11]]])\n",
      "torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "s2_init = AveargeJoint()\n",
    "x_2 = s2_init(out_t)\n",
    "print(x_2)\n",
    "print(x_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class AveargeJoint(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        self.torso = [8,9,10]\n",
    "        self.left_leg_up = [0,1]\n",
    "        self.left_leg_down = [2,3]\n",
    "        self.right_leg_up = [4,5]\n",
    "        self.right_leg_down = [6,7]\n",
    "        self.head = [11,12,13]\n",
    "        self.left_arm_up = [14,15]\n",
    "        self.left_arm_down = [16,17,18,19]\n",
    "        self.right_arm_up = [20,21]\n",
    "        self.right_arm_down = [22,23,24,25]\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x_part = torch.tensor([])\n",
    "        for i in range(1,6):\n",
    "            x_temp1 = F.avg_pool2d(x[:, :, (i*2,i*2+1)], kernel_size=(1, 2))\n",
    "            x_part = torch.cat((x_part,x_temp1),dim = -1)\n",
    "            \n",
    "        return x_part\n",
    "\n",
    "\n",
    "        '''\n",
    "        x_torso = F.avg_pool2d(x[:, :, self.torso], kernel_size=(1, 3))                                              # [N, C, T, V=1]\n",
    "        x_leftlegup = F.avg_pool2d(x[:, :, self.left_leg_up], kernel_size=(1, 2))                                # [N, C, T, V=1]\n",
    "        x_leftlegdown = F.avg_pool2d(x[:, :, self.left_leg_down], kernel_size=(1, 2))                     # [N, C, T, V=1]\n",
    "        x_rightlegup = F.avg_pool2d(x[:,  :, self.right_leg_up], kernel_size=(1, 2))                        # [N, C, T, V=1]\n",
    "        x_rightlegdown = F.avg_pool2d(x[ :, :, self.right_leg_down], kernel_size=(1, 2))                   # [N, C, T, V=1]\n",
    "        x_head = F.avg_pool2d(x[ :, :, self.head], kernel_size=(1, 3))                                              # [N, C, T, V=1]\n",
    "        x_leftarmup = F.avg_pool2d(x[ :, :, self.left_arm_up], kernel_size=(1, 2))                            # [N, C, T, V=1]\n",
    "        x_leftarmdown = F.avg_pool2d(x[ :, :, self.left_arm_down], kernel_size=(1, 4))                 # [N, C, T, V=1]\n",
    "        x_rightarmup = F.avg_pool2d(x[ :, :, self.right_arm_up], kernel_size=(1, 2))                        # [N, C, T, V=1]\n",
    "        x_rightarmdown = F.avg_pool2d(x[ :, :, self.right_arm_down], kernel_size=(1, 4))               # [N, C, T, V=1]\n",
    "        x_part = torch.cat((x_leftlegup, x_leftlegdown, x_rightlegup, x_rightlegdown, x_torso, x_head, x_leftarmup, x_leftarmdown, x_rightarmup, x_rightarmdown), dim=-1)               # [N, C, T, V=1]), dim=-1)        # [N, C, T, 10]\n",
    "        return x_part\n",
    "    \n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1., 10., 11.,  2.,  4.],\n",
      "         [ 3.,  6.,  6.,  7., 14.],\n",
      "         [12., 12.,  5., 12., 12.]],\n",
      "\n",
      "        [[ 1.,  7.,  7.,  3.,  8.],\n",
      "         [10., 10.,  6.,  9., 10.],\n",
      "         [13., 11., 10., 10., 11.]]])\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "s2_init = AveargeJoint()\n",
    "x_2 = s2_init(out_t)\n",
    "print(x_2)\n",
    "print(x_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.,  7.,  8.,  3.,  3.,  3.,  8.,  6.,  9.,  5.],\n",
      "         [ 4.,  8., 10.,  6.,  7.,  8., 12.,  7.,  9.,  9.],\n",
      "         [ 9.,  8., 15., 14., 14., 10., 10., 13., 15., 16.]],\n",
      "\n",
      "        [[ 5.,  5.,  6.,  6.,  6.,  4.,  6.,  5.,  8.,  9.],\n",
      "         [ 7., 10.,  7., 12., 11., 11.,  9.,  7., 10., 13.],\n",
      "         [ 7., 11.,  8., 10.,  9., 14.,  9., 16., 14., 14.]]])\n",
      "torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class AveargeJoint(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_part = torch.tensor([])\n",
    "        for i in range(0,10):\n",
    "            x_temp1 = F.avg_pool2d(x[:, :, (i*3,i*3+1,i*3+2)], kernel_size=(1, 3))\n",
    "            x_part = torch.cat((x_part,x_temp1),dim = -1)\n",
    "            \n",
    "        return x_part\n",
    "    \n",
    "s2_init = AveargeJoint()\n",
    "x_2 = s2_init(out_t)\n",
    "print(x_2)\n",
    "print(x_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartLocalInform(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.torso = [8,9,10]\n",
    "        self.left_leg_up = [0,1]\n",
    "        self.left_leg_down = [2,3]\n",
    "        self.right_leg_up = [4,5]\n",
    "        self.right_leg_down = [6,7]\n",
    "        self.head = [11,12,13]\n",
    "        self.left_arm_up = [14,15]\n",
    "        self.left_arm_down = [16,17,18,19]\n",
    "        self.right_arm_up = [20,21]\n",
    "        #self.right_arm_down = [22,23,24,25]\n",
    "        self.right_arm_down = [22,23,24,25,26,27,28,29]\n",
    "\n",
    "    def forward(self, part):\n",
    "        N, d, T, w = part.size()  # [64, 256, 7, 10]\n",
    "\n",
    "        #x = part.new_zeros((N, d, T, 26))\n",
    "        x = part.new_zeros((N, d, T, 30))\n",
    "\n",
    "        x[:,:,:,self.left_leg_up] = torch.cat((part[:,:,:,0].unsqueeze(-1), part[:,:,:,0].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.left_leg_down] = torch.cat((part[:,:,:,1].unsqueeze(-1), part[:,:,:,1].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.right_leg_up] = torch.cat((part[:,:,:,2].unsqueeze(-1), part[:,:,:,2].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.right_leg_down] = torch.cat((part[:,:,:,3].unsqueeze(-1), part[:,:,:,3].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.torso] = torch.cat((part[:,:,:,4].unsqueeze(-1), part[:,:,:,4].unsqueeze(-1), part[:,:,:,4].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.head] = torch.cat((part[:,:,:,5].unsqueeze(-1), part[:,:,:,5].unsqueeze(-1), part[:,:,:,5].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.left_arm_up] = torch.cat((part[:,:,:,6].unsqueeze(-1),part[:,:,:,6].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.left_arm_down] = torch.cat((part[:,:,:,7].unsqueeze(-1), part[:,:,:,7].unsqueeze(-1), part[:,:,:,7].unsqueeze(-1), part[:,:,:,7].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.right_arm_up] = torch.cat((part[:,:,:,8].unsqueeze(-1), part[:,:,:,8].unsqueeze(-1)),-1)\n",
    "        x[:,:,:,self.right_arm_down] = torch.cat((part[:,:,:,9].unsqueeze(-1), part[:,:,:,9].unsqueeze(-1), part[:,:,:,9].unsqueeze(-1), part[:,:,:,9].unsqueeze(-1),part[:,:,:,9].unsqueeze(-1), part[:,:,:,9].unsqueeze(-1), part[:,:,:,9].unsqueeze(-1), part[:,:,:,9].unsqueeze(-1)),-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartLocalInform(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        self.torso = [8,9,10]\n",
    "        self.left_leg_up = [0,1]\n",
    "        self.left_leg_down = [2,3]\n",
    "        self.right_leg_up = [4,5]\n",
    "        self.right_leg_down = [6,7]\n",
    "        self.head = [11,12,13]\n",
    "        self.left_arm_up = [14,15]\n",
    "        self.left_arm_down = [16,17,18,19]\n",
    "        self.right_arm_up = [20,21]\n",
    "        #self.right_arm_down = [22,23,24,25]\n",
    "        self.right_arm_down = [22,23,24,25,26,27,28,29]\n",
    "        '''\n",
    "\n",
    "    def forward(self, part):\n",
    "        N, d, T, w = part.size()  # [64, 256, 7, 10]\n",
    "\n",
    "        #x = part.new_zeros((N, d, T, 26))\n",
    "        x = part.new_zeros((N, d, T, 30))\n",
    "\n",
    "        for i in range(0,10):\n",
    "            x[:,:,:,(i*3,i*3+1,i*3+2)] = torch.cat((part[:,:,:,i].unsqueeze(-1), part[:,:,:,i].unsqueeze(-1)),part[:,:,:,i].unsqueeze(-1),-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3_new/envs/scgnnEnv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_10kb.txt\n",
      "[[   10     9     1]\n",
      " [   18    13     1]\n",
      " [   18    18     1]\n",
      " ...\n",
      " [19226 19063     1]\n",
      " [19226 19223     1]\n",
      " [19229 19061     1]]\n",
      "[   10    18    18 ... 19226 19226 19229] [    9    13    18 ... 19063 19223 19061] [1 1 1 ... 1 1 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(200, 200)\n",
      "/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/cortex-p007-cb_067.hic_chrom1_10kb.txt\n",
      "[[   14    10     1]\n",
      " [   19    19     1]\n",
      " [   20    20     1]\n",
      " ...\n",
      " [19228 19228     1]\n",
      " [19230 19230     1]\n",
      " [19236 19233     1]]\n",
      "[   14    19    20 ... 19228 19230 19236] [   10    19    20 ... 19228 19230 19233] [1 1 1 ... 1 1 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(200, 200)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import os\n",
    "\n",
    "import hicstraw\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import math\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.utils import convert\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def load_data(cell_id, chrom):\n",
    "    #root = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test\" # 文件夹路径，相对路径or绝对路径都可以\n",
    "    root = r\"/data_disk/data/GSE162511\"\n",
    "    # 获取文件夹所有文件\n",
    "    files_list = os.listdir(root) # 示例 [\"1.txt\",\"2.txt\",\"2.gif\",\"child_folder_name\",\"2.jpg\"]\n",
    "\n",
    "    ## 常见操作\n",
    "    # 1.获取指定后缀（如txt）的文件\n",
    "    filter_files_list = [fn for fn in files_list if fn.endswith(\".hic\")]\n",
    "    #print(filter_files_list_10kb)\n",
    "    test = filter_files_list[0:2]\n",
    "    for i in test:\n",
    "    \n",
    "        file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/\"+str(i)+\"_chrom\"+str(chrom)+\"_10kb.txt\"\n",
    "        print(file_path_test)\n",
    "        data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "        print(data_test)\n",
    "        col = data_test[:,0]\n",
    "        row  = data_test[:,1]\n",
    "        value = data_test[:,2]\n",
    "        print(col,row,value)\n",
    "\n",
    "        max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "        sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "        #print(sp_coo_m)\n",
    "        up_delta = sp_coo_m.todense()\n",
    "        down_delta = up_delta.transpose()\n",
    "        diag1 = np.diagonal(up_delta)\n",
    "        diagn = np.diag(diag1)\n",
    "        complete_matrix = up_delta + down_delta - diagn\n",
    "        print(complete_matrix)\n",
    "        #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "        #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "        complete_matrix_10kb_test  = complete_matrix[0:200,0:200]\n",
    "        print(complete_matrix_10kb_test)\n",
    "        print(complete_matrix_10kb_test.shape)\n",
    "        #np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_200.txt\", complete_matrix_10kb_test,fmt='%d',delimiter=',')\n",
    "    '''\n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_50kb.txt\"\n",
    "    print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    print(col,row,value)\n",
    "\n",
    "    max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    print(complete_matrix)\n",
    "    #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "    complete_matrix_50kb_test  = complete_matrix[0:40,0:40]\n",
    "    np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_40.txt\", complete_matrix_50kb_test,fmt='%d',delimiter=',')\n",
    "\n",
    "    file_path_test = r\"/data_disk/zhangqq/josie-gnn-code/recomb/2-try-dmgnn/data_test/hippocampus-p056-cb_059.hic_chrom1_100kb.txt\"\n",
    "    print(file_path_test)\n",
    "    data_test = np.loadtxt(file_path_test,dtype=int,delimiter='\\t')\n",
    "    print(data_test)\n",
    "    col = data_test[:,0]\n",
    "    row  = data_test[:,1]\n",
    "    value = data_test[:,2]\n",
    "    print(col,row,value)\n",
    "\n",
    "    max_nodes = int(max(max(col),max(row))+1)\n",
    "\n",
    "    sp_coo_m = sp.coo_matrix((value,(row,col)),shape = (max_nodes,max_nodes))\n",
    "    #print(sp_coo_m)\n",
    "    up_delta = sp_coo_m.todense()\n",
    "    down_delta = up_delta.transpose()\n",
    "    diag1 = np.diagonal(up_delta)\n",
    "    diagn = np.diag(diag1)\n",
    "    complete_matrix = up_delta + down_delta - diagn\n",
    "    print(complete_matrix)\n",
    "    #t_complete_matrix = torch.from_numpy(complete_matrix)\n",
    "    #t_complete_matrix_100kb = t_complete_matrix.unsqueeze(dim=0)\n",
    "    complete_matrix_100kb_test  = complete_matrix[0:20,0:20]\n",
    "    np.savetxt(\"/data_disk/zhangqq/josie-gnn-code/recomb/3-try-dmgnn/data/hic_matrix/nodes_20.txt\", complete_matrix_100kb_test,fmt='%d',delimiter=',')\n",
    "    \n",
    "    return complete_matrix_10kb_test,complete_matrix_50kb_test\n",
    "    '''\n",
    "\n",
    "\n",
    "x = load_data(0,1)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgnnEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
